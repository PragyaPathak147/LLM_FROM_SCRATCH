{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7kizeZuWjTm"
      },
      "source": [
        "## Step 1: Creating Tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B7KLLTUWjTn",
        "outputId": "0f0f6372-cc62-4def-b792-98a6e39f2f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of character: 439478\n",
            "M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly nor\n"
          ]
        }
      ],
      "source": [
        "with open(\"harrypotter.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "print(\"Total number of character:\", len(raw_text))\n",
        "print(raw_text[:99])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni_WuaU4WjTx"
      },
      "source": [
        "### BYTE PAIR ENCODING (BPE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5JHrDMwWjTx",
        "outputId": "001f3446-5219-406b-9329-1cc36a483105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "! pip3 install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZxvU0ayWjTx",
        "outputId": "3f645066-eff8-4020-cf3b-a3f50416a02c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiktoken version: 0.9.0\n"
          ]
        }
      ],
      "source": [
        "import importlib\n",
        "import tiktoken\n",
        "\n",
        "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "sxfC__YiWjTy"
      },
      "outputs": [],
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_SOC3dSWjTy",
        "outputId": "eb9ddeda-fb36-4497-c644-733203d834e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 810, 389, 345, 1016, 220, 220, 50256, 1282, 284, 711, 351, 514]\n"
          ]
        }
      ],
      "source": [
        "text = (\n",
        "    \"Hello where are you going  <|endoftext|> come to play with us\"\n",
        ")\n",
        "\n",
        "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "print(integers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85Oe44BxWjTy",
        "outputId": "bb35767c-78ab-4650-b528-5fbaacd6b9ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello where are you going  <|endoftext|> come to play with us\n"
          ]
        }
      ],
      "source": [
        "strings = tokenizer.decode(integers)\n",
        "\n",
        "print(strings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy2Ug1XBWjTy",
        "outputId": "43e689f4-1738-43d8-d2c8-3d1824dfa1a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[28015, 15908, 266, 86, 1259]\n",
            "mkdir ww ty\n"
          ]
        }
      ],
      "source": [
        "integers = tokenizer.encode(\"mkdir ww ty\")\n",
        "print(integers)\n",
        "\n",
        "strings = tokenizer.decode(integers)\n",
        "print(strings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xqx7jaZWjTy"
      },
      "source": [
        "### CREATING INPUT-TARGET PAIRS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZrPyTGIWjTz",
        "outputId": "93ed0e70-ca36-4999-e663-2b5e66be8c3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "124336\n"
          ]
        }
      ],
      "source": [
        "with open(\"harrypotter.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "enc_text = tokenizer.encode(raw_text)\n",
        "print(len(enc_text))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.n_vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9X_cf5Bi-cd",
        "outputId": "7a24c829-a1f3-4967-d462-e0bcfecbf6fc"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50257"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "lsiKy2CbWjTz"
      },
      "outputs": [],
      "source": [
        "enc_sample = enc_text[50:] # to increase randomness\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdlGt5dpWjTz",
        "outputId": "61c05cdb-6a3d-4bfd-c8b5-f4e8a82635bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: [11428, 11, 780, 484]\n",
            "y:      [11, 780, 484, 655]\n"
          ]
        }
      ],
      "source": [
        "context_size = 4 #length of the input\n",
        "#The context_size of 4 means that the model is trained to look at a sequence of 4 words (or tokens)\n",
        "#to predict the next word in the sequence.\n",
        "#The input x is the first 4 tokens [1, 2, 3, 4], and the target y is the next 4 tokens [2, 3, 4, 5]\n",
        "\n",
        "x = enc_sample[:context_size]\n",
        "y = enc_sample[1:context_size+1]\n",
        "\n",
        "print(f\"x: {x}\")\n",
        "print(f\"y:      {y}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTJAdsmZWjTz",
        "outputId": "7c28d075-fe73-4d4a-ed8e-2c61f9b68629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11428] ----> 11\n",
            "[11428, 11] ----> 780\n",
            "[11428, 11, 780] ----> 484\n",
            "[11428, 11, 780, 484] ----> 655\n"
          ]
        }
      ],
      "source": [
        "for i in range(1, context_size+1):\n",
        "    context = enc_sample[:i]\n",
        "    desired = enc_sample[i]\n",
        "\n",
        "    print(context, \"---->\", desired)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXIzDM69WjTz",
        "outputId": "5bbcc5e2-250f-42e4-bb53-11b355262b7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " mysterious ----> ,\n",
            " mysterious, ---->  because\n",
            " mysterious, because ---->  they\n",
            " mysterious, because they ---->  just\n"
          ]
        }
      ],
      "source": [
        "for i in range(1, context_size+1):\n",
        "    context = enc_sample[:i]\n",
        "    desired = enc_sample[i]\n",
        "\n",
        "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifvaA7AiWjT0"
      },
      "source": [
        "### IMPLEMENTING A DATA LOADER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "tWxw89E0WjT0"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text \"harrypotter.txt\"\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into sequences, stride is how much tokens the window slides\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "NgX72cwSWjT0"
      },
      "outputs": [],
      "source": [
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,  #drops the last batch if it is shorter than the specified batch_size to prevent loss spikes during training\n",
        "        num_workers=num_workers  #The number of CPU processes to use for preprocessing\n",
        "    )\n",
        "\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLYi_nW8WjT0",
        "outputId": "1762a62b-28cb-40e7-ce15-4a24a5a8abd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[   44,   374,    13,  ..., 36766,   673,  1422],\n",
            "        [ 1625,   287,   845,  ...,   674,  1621,  4940],\n",
            "        [  447,   247,    83,  ...,   780, 37198,   373],\n",
            "        [   11,   612,   373,  ...,   612,  2492,   447]]), tensor([[  374,    13,   290,  ...,   673,  1422,   447],\n",
            "        [  287,   845,  4465,  ...,  1621,  4940,    11],\n",
            "        [  247,    83,   423,  ..., 37198,   373,   783],\n",
            "        [  612,   373,  2147,  ...,  2492,   447,   247]])]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=4, max_length=256, stride=128, shuffle=False\n",
        ")\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P3cq5aUWjT1",
        "outputId": "c9798fd2-2e4b-45bb-c624-66e4342215d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            " tensor([[   44,   374,    13,   290],\n",
            "        [ 9074,    13,   360,  1834],\n",
            "        [ 1636,    11,   286,  1271],\n",
            "        [ 1440,    11,  4389, 16809],\n",
            "        [ 9974,    11,   547,  6613],\n",
            "        [  284,   910,   326,   484],\n",
            "        [  547,  7138,  3487,    11],\n",
            "        [ 5875,   345,   845,   881]])\n",
            "\n",
            "Targets:\n",
            " tensor([[  374,    13,   290,  9074],\n",
            "        [   13,   360,  1834,  1636],\n",
            "        [   11,   286,  1271,  1440],\n",
            "        [   11,  4389, 16809,  9974],\n",
            "        [   11,   547,  6613,   284],\n",
            "        [  910,   326,   484,   547],\n",
            "        [ 7138,  3487,    11,  5875],\n",
            "        [  345,   845,   881,    13]])\n"
          ]
        }
      ],
      "source": [
        "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "print(\"Inputs:\\n\", inputs)\n",
        "print(\"\\nTargets:\\n\", targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsmlxkt9WjT1"
      },
      "source": [
        "### CREATING TOKEN EMBEDDINGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Xz1yJclyWjT1"
      },
      "outputs": [],
      "source": [
        "vocab_size = 50257\n",
        "output_dim = 768\n",
        "\n",
        "torch.manual_seed(123)\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88gnIYlxWjT1",
        "outputId": "5e41a845-9391-47cd-e39a-eb0e560027af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 3.3737e-01, -1.7778e-01, -3.0353e-01,  ..., -3.1812e-01,\n",
            "         -1.3936e+00,  5.2262e-01],\n",
            "        [ 2.5787e-01,  3.4197e-01, -8.1678e-01,  ..., -4.0981e-01,\n",
            "          4.9785e-01, -3.7207e-01],\n",
            "        [ 7.9574e-01,  5.3501e-01,  9.4275e-01,  ..., -1.0749e+00,\n",
            "          9.5492e-02, -1.4138e+00],\n",
            "        ...,\n",
            "        [-7.1278e-01, -5.0190e-01,  1.4119e+00,  ..., -1.4979e-01,\n",
            "         -4.8977e-01, -1.0620e+00],\n",
            "        [ 2.0646e+00,  1.1190e+00,  3.8486e-01,  ..., -7.2015e-01,\n",
            "         -5.5703e-01,  9.8639e-01],\n",
            "        [ 1.1364e-03, -7.5320e-01, -1.7924e-01,  ..., -3.2443e-01,\n",
            "          2.6055e-01,  5.8885e-01]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(token_embedding_layer.weight)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o44X9whxWjT1",
        "outputId": "2cda7373-495c-4dbe-c98e-b0fc01ecf5ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-3.1186e-02,  1.6913e+00, -2.2380e+00,  1.5100e+00, -1.3988e+00,\n",
            "         -8.6170e-02, -1.0665e+00,  3.9668e-01,  4.3065e-01, -4.1438e-01,\n",
            "         -3.1839e-01,  2.0454e+00,  7.2016e-01, -8.5287e-01,  5.8417e-01,\n",
            "         -7.2265e-01, -1.4753e+00,  6.8972e-02,  8.0555e-01,  1.3240e+00,\n",
            "         -9.8045e-01, -1.2199e+00, -9.3244e-01, -5.0473e-01, -7.9787e-01,\n",
            "          2.2975e-01,  4.1912e-01,  2.7533e-01,  3.4339e-02, -1.4618e+00,\n",
            "          1.3078e+00,  3.2857e-01, -2.2494e-01, -2.8510e+00, -2.4963e-01,\n",
            "         -9.1632e-01,  2.1671e+00, -9.3249e-01,  1.9403e+00,  1.1822e+00,\n",
            "         -2.3286e+00,  4.1231e-02, -1.0138e+00,  8.3503e-02, -1.4837e+00,\n",
            "         -5.5533e-01, -1.9864e+00,  1.4011e+00, -1.8653e+00,  4.0254e-03,\n",
            "          4.1516e-01, -6.6000e-01, -1.0517e+00,  5.8994e-01,  2.8082e-01,\n",
            "         -2.2997e-01, -5.4657e-01,  1.6418e+00,  4.0352e-01,  1.4848e+00,\n",
            "         -9.1545e-01, -5.3633e-01, -3.1294e-01,  1.2653e+00, -2.5450e+00,\n",
            "          6.8583e-01, -2.1797e-02, -3.7363e-01,  3.3058e-01,  5.7090e-01,\n",
            "         -1.6473e+00,  5.5692e-01,  1.1120e+00,  1.5448e-01, -2.7359e-01,\n",
            "          1.2529e-01, -1.4560e+00,  4.4454e-01, -6.0652e-01, -2.4604e-01,\n",
            "          8.1248e-01, -6.7957e-01, -6.5700e-02,  3.2254e-01, -3.3028e-01,\n",
            "          1.8858e+00, -1.4886e+00,  1.3860e+00,  9.5060e-01, -9.6647e-03,\n",
            "          6.9634e-01,  7.0754e-02, -1.2871e+00, -5.0424e-02,  8.7272e-02,\n",
            "         -5.5994e-01,  1.1836e+00, -8.4068e-01,  5.1523e-02,  4.0327e-01,\n",
            "          5.6901e-01,  1.0067e-01,  2.0811e-01,  5.8022e-02, -1.2779e+00,\n",
            "         -2.6224e-01, -1.0239e+00, -8.3791e-02, -4.5801e-02, -4.5636e-01,\n",
            "         -1.1088e+00, -1.4794e+00,  1.1937e-01, -7.0806e-01,  6.2806e-01,\n",
            "          6.0496e-01, -2.9804e+00, -7.2261e-01, -6.0460e-01, -8.0034e-01,\n",
            "         -1.1957e+00,  3.0030e-01,  3.4821e-02, -1.2973e-01, -1.3096e+00,\n",
            "          1.4597e+00, -7.8116e-01, -2.5286e-01, -7.4371e-02, -3.5022e-01,\n",
            "         -7.0196e-01,  1.1352e+00,  9.2812e-01, -7.6526e-01,  7.2431e-01,\n",
            "         -1.9868e+00, -7.8110e-01,  1.4682e+00,  1.6340e+00, -1.5233e-01,\n",
            "         -1.1067e-01, -1.1495e+00,  2.0928e-01,  1.3444e+00,  7.8444e-01,\n",
            "         -1.4659e+00, -6.4601e-01,  9.5425e-01,  2.7012e+00, -1.9309e+00,\n",
            "          6.3512e-01, -1.0244e+00,  1.0328e+00, -1.4612e+00,  2.2278e+00,\n",
            "         -1.0470e+00,  1.3682e-01,  1.4992e+00,  1.6377e+00, -1.6372e+00,\n",
            "         -2.0610e-01,  3.1609e-01, -2.8122e+00,  5.1939e-02,  8.8693e-01,\n",
            "          5.8303e-01,  1.1372e+00,  1.1049e+00,  1.7068e+00,  1.6554e+00,\n",
            "         -1.3100e+00,  5.6737e-01,  9.1848e-01, -6.7500e-01,  1.0585e+00,\n",
            "          2.3530e-01,  9.5206e-02, -2.6112e-01,  3.1466e-01, -2.0658e-02,\n",
            "         -4.7375e-01,  1.0879e+00, -2.2311e-01,  3.9380e-01,  3.9600e-01,\n",
            "         -6.0441e-01, -4.0223e-02,  1.1670e+00,  3.9556e-01, -2.3827e-01,\n",
            "         -3.9653e-01,  1.1497e+00,  8.4130e-01,  3.8152e-01,  1.9359e+00,\n",
            "          2.1805e-01, -8.1659e-01,  1.8322e+00,  2.0568e-01, -3.8023e-01,\n",
            "         -4.9021e-01, -2.8254e-01, -1.9285e-01, -1.0167e+00,  1.4106e+00,\n",
            "         -1.9721e+00, -8.0295e-01, -9.0108e-02, -2.1720e+00, -9.5700e-01,\n",
            "          3.0745e-01, -7.6679e-01,  8.5417e-02, -6.5124e-01, -4.9673e-01,\n",
            "         -6.6417e-02, -6.6501e-01,  1.1731e+00,  2.1823e-01, -1.7372e+00,\n",
            "         -7.4604e-01, -2.3411e-01,  3.9444e-01, -1.2550e+00,  2.9904e-01,\n",
            "          5.4894e-01, -2.3020e+00, -1.1938e-01, -1.2611e+00,  3.5343e-01,\n",
            "         -5.7374e-01, -1.1939e+00,  6.1136e-01, -1.8089e+00,  8.8208e-01,\n",
            "         -5.8628e-01,  1.5595e+00, -1.5140e-01,  1.0214e+00,  8.9337e-01,\n",
            "         -2.7096e-01,  5.7997e-01,  1.9421e+00,  1.3161e+00,  1.1080e+00,\n",
            "          4.4078e-01,  3.5481e-01, -4.6659e-01,  4.0399e-01,  4.5127e-03,\n",
            "          5.2327e-01, -9.0775e-01,  4.3088e-02, -1.3748e+00, -1.2065e+00,\n",
            "          4.2180e-01,  1.4252e+00, -1.0995e-01,  2.4549e-01,  1.1445e+00,\n",
            "         -7.5669e-02,  1.0923e+00,  1.3963e-01,  5.8567e-02,  1.5150e+00,\n",
            "          4.1877e-01, -1.6213e-01,  1.3445e+00,  2.5718e+00,  1.0574e+00,\n",
            "         -1.9661e-01, -1.3912e-01,  1.5396e+00,  2.0672e+00, -1.1890e+00,\n",
            "         -1.5933e-01,  7.8735e-01, -8.6895e-02, -1.4776e+00,  9.1489e-02,\n",
            "          1.5729e+00,  2.4649e-02, -5.7467e-01, -1.0743e+00,  3.0157e-01,\n",
            "         -8.3011e-01, -1.3470e+00, -1.4028e+00,  8.2265e-01, -7.5501e-02,\n",
            "         -1.2635e+00, -8.7559e-01,  9.5133e-01,  5.2592e-02,  4.3662e-01,\n",
            "         -6.9294e-01,  5.4734e-01, -3.9198e-01, -1.8835e+00, -1.3389e+00,\n",
            "          3.3270e-02, -2.9391e-01,  1.2392e+00, -7.0776e-01,  1.8380e+00,\n",
            "         -7.0283e-02, -5.4473e-01,  3.4574e+00, -8.6320e-01,  9.2544e-01,\n",
            "          1.9603e-01, -9.3060e-01,  1.6643e-01, -1.7327e+00,  1.7624e-01,\n",
            "          1.6495e+00, -5.0368e-01,  6.1651e-01, -2.8783e-01, -2.0862e+00,\n",
            "         -1.1725e+00,  2.7841e-01, -4.8225e-01,  1.3662e+00, -3.6233e-01,\n",
            "          3.0020e-02, -1.3593e+00,  7.4376e-01,  1.5423e+00,  8.9674e-01,\n",
            "         -6.7856e-01,  1.0021e+00, -1.4268e+00, -5.2033e-01,  3.5146e-01,\n",
            "         -1.7962e+00, -1.7005e+00, -7.2256e-01,  5.8458e-01,  2.7271e-01,\n",
            "         -1.5195e+00, -2.8320e-01, -4.4675e-01, -8.7400e-01,  9.2685e-01,\n",
            "          2.8763e+00,  2.9204e-01, -1.3412e+00, -1.2287e-01,  7.4189e-01,\n",
            "          1.3037e+00,  3.4048e-01, -1.4581e+00, -1.2640e+00, -1.2075e+00,\n",
            "          3.2827e-01, -8.9568e-01, -3.7690e+00,  3.0835e-01, -3.8973e-01,\n",
            "          9.5670e-01,  5.4289e-01,  9.4825e-01, -4.9640e-01, -8.4203e-01,\n",
            "          3.3672e-01, -5.3885e-01,  1.3521e+00,  6.1604e-02, -1.0121e+00,\n",
            "         -6.9171e-01,  1.8143e-01, -9.2015e-01, -1.3709e+00,  5.9341e-01,\n",
            "         -1.4484e+00,  8.6797e-01,  6.3144e-02, -2.4008e-01,  2.9098e-02,\n",
            "          2.0429e-01, -3.2400e-01,  1.5553e-01, -5.1329e-01,  1.4663e+00,\n",
            "          3.8876e-01,  5.2439e-01, -6.7198e-01,  1.2702e+00,  1.4745e-01,\n",
            "         -6.7557e-01,  1.0647e+00,  4.1219e-01,  4.3603e-01,  4.7105e-01,\n",
            "          1.7838e+00, -2.8896e-01, -1.9429e-01, -4.3206e-01,  1.5522e-01,\n",
            "         -2.9009e-01,  6.9561e-01,  3.8703e-01,  1.3461e+00,  3.0132e+00,\n",
            "          9.3456e-01, -2.4039e+00, -5.2083e-02, -7.1226e-01, -9.9023e-01,\n",
            "          1.6379e+00,  2.4461e-01, -4.7326e-01,  1.0840e+00, -1.7153e-01,\n",
            "         -1.9957e+00, -7.1395e-01,  2.2886e-01, -5.8806e-01,  2.2581e+00,\n",
            "         -5.8018e-01,  1.4646e+00,  3.9223e-02, -7.2949e-01,  4.9820e-01,\n",
            "         -1.1848e+00,  4.2860e-01, -7.6736e-02,  1.2760e+00, -1.3223e+00,\n",
            "          6.2653e-02,  3.6172e-01, -7.0709e-01,  9.4912e-02, -5.6145e-01,\n",
            "         -6.2474e-01,  1.0816e+00,  7.2351e-01, -9.1308e-01,  6.7588e-01,\n",
            "          9.9935e-02, -9.3659e-01,  1.9773e+00,  1.2333e+00,  1.2868e-01,\n",
            "         -1.0535e+00, -1.6376e+00,  7.9701e-01,  1.3612e-01, -7.1445e-02,\n",
            "         -2.3242e-01, -8.2159e-01,  1.4716e+00, -6.7776e-02,  4.3092e-01,\n",
            "         -1.2569e-01,  2.3477e-01, -1.3550e+00,  3.3390e-01,  2.1095e+00,\n",
            "          1.8534e+00, -8.0275e-01,  6.1036e-01,  8.8443e-01, -4.3619e-01,\n",
            "          4.5869e-01,  4.1768e-01,  1.4428e+00,  6.3396e-03, -2.0022e-01,\n",
            "          4.5574e-01,  4.2212e-01, -1.5692e+00, -5.9606e-01, -7.1028e-01,\n",
            "         -9.2299e-01,  1.2269e-01, -5.5695e-02, -1.6945e-02,  9.8158e-01,\n",
            "          1.7746e-01,  8.7806e-01, -2.7163e+00, -1.1701e-01, -4.8946e-01,\n",
            "         -4.2432e-01,  5.7536e-01, -2.2821e-01,  2.8672e-01,  4.2956e-01,\n",
            "         -1.3569e+00, -4.2962e-01,  5.0403e-01, -1.0372e+00,  1.0028e+00,\n",
            "         -1.2460e+00, -1.2847e-01, -1.9543e+00, -1.0806e+00,  2.8702e+00,\n",
            "          3.6586e-01, -1.1613e+00,  4.6796e-01,  1.3076e-01,  1.0111e+00,\n",
            "         -1.1194e+00, -1.4237e+00, -1.2461e+00, -2.0593e-01, -1.8122e+00,\n",
            "         -2.5448e+00, -5.1354e-01,  1.8056e+00, -1.0064e+00,  1.5822e-01,\n",
            "          6.7008e-03, -7.3839e-02, -1.1293e+00,  2.0071e-01, -7.2191e-01,\n",
            "          1.1475e+00,  9.8659e-01,  7.3272e-01,  8.1606e-01,  3.0163e-02,\n",
            "         -1.4042e+00,  1.5829e+00,  1.6755e+00, -1.0043e+00, -1.4942e+00,\n",
            "          1.0601e+00, -6.1171e-01,  7.5617e-01, -7.6327e-01, -1.8129e+00,\n",
            "         -9.5914e-01,  7.0806e-01,  1.3913e+00, -3.4828e-01, -1.3113e+00,\n",
            "          1.4175e+00,  3.8275e-01,  2.0482e+00,  3.5412e-01,  1.1058e+00,\n",
            "          8.8305e-01,  1.1274e+00, -1.0824e-01, -2.1955e-01,  6.7616e-01,\n",
            "          1.1471e+00,  7.6909e-01,  1.9868e+00, -1.2863e-02, -6.1966e-01,\n",
            "          5.5233e-01,  2.3189e-01, -4.9003e-01,  2.8418e-01,  1.1051e+00,\n",
            "          2.3333e+00,  3.8119e-02, -2.3219e+00, -8.1724e-01,  1.3642e+00,\n",
            "         -2.4666e-01, -9.3438e-01, -8.1166e-02,  2.7267e-01,  2.7873e+00,\n",
            "          5.3567e-02,  2.0319e+00, -1.6579e+00,  1.2799e+00, -6.4516e-01,\n",
            "          1.1678e+00,  1.7109e+00, -1.2734e-01, -5.8256e-01,  1.0403e+00,\n",
            "          3.6280e-01, -9.5510e-01,  8.7138e-01, -3.7592e-01,  4.6748e-02,\n",
            "         -3.4300e-01, -1.4552e+00,  2.4881e+00, -8.0842e-01, -2.1746e+00,\n",
            "          8.7757e-01,  2.3966e-01, -5.4877e-01, -9.7709e-01, -1.0217e+00,\n",
            "          2.0075e+00, -1.2168e+00,  1.7594e+00,  1.0822e+00,  8.3537e-01,\n",
            "          4.3317e-01, -1.6106e+00, -5.3597e-02, -1.7629e+00,  3.5692e-01,\n",
            "         -1.3356e-02, -2.0325e+00, -7.0423e-01,  7.2286e-01,  7.3021e-01,\n",
            "          1.8748e+00,  4.5545e-01,  2.1323e+00,  7.8181e-01, -9.4716e-01,\n",
            "         -1.7032e+00, -7.4578e-01,  9.0756e-01, -8.3236e-01, -8.1265e-01,\n",
            "          2.2806e-02, -9.4910e-01, -1.2213e+00, -1.4307e+00,  5.4982e-02,\n",
            "          8.5972e-01,  7.2072e-01, -1.2701e+00, -1.1478e+00,  1.9779e-01,\n",
            "         -1.8320e+00, -1.8891e-01, -3.7714e-01, -4.7899e-01, -1.6028e+00,\n",
            "         -2.8849e-01, -1.2788e+00, -4.5685e-01,  3.8879e-01,  1.3338e+00,\n",
            "         -1.4237e-01,  6.6563e-02,  9.2206e-01,  1.8109e-01, -8.3383e-01,\n",
            "         -1.5771e+00,  8.5299e-01,  1.1082e+00, -1.8441e+00,  1.2924e+00,\n",
            "         -5.9390e-01, -4.7219e-02,  4.8337e-01, -3.3350e+00,  6.2161e-01,\n",
            "          8.6495e-01,  1.2403e+00,  4.3563e-01, -1.8498e-01, -1.8945e+00,\n",
            "         -3.0117e+00, -2.6966e-01, -4.0831e-01, -2.2674e+00,  4.4732e-01,\n",
            "         -9.1638e-02,  8.7619e-01, -3.6456e-01,  3.0179e-01,  1.1550e+00,\n",
            "         -1.0142e+00,  9.6602e-01, -6.5363e-01,  1.5311e-01, -1.3949e+00,\n",
            "          2.9362e-01,  4.1843e-01, -9.8013e-02,  2.7055e+00, -4.5915e-01,\n",
            "         -1.0419e+00, -1.0073e+00,  7.7435e-01, -5.8198e-01,  2.4523e-01,\n",
            "          7.6472e-01, -1.3979e+00,  1.1708e+00,  4.4886e-01, -1.3396e-01,\n",
            "         -1.7715e-01,  5.9816e-01,  5.5806e-01,  1.2676e-01,  2.6668e+00,\n",
            "         -1.3954e+00, -4.7441e-01, -1.3016e-01,  1.0919e-01,  1.1326e+00,\n",
            "          7.0819e-02,  4.8289e-02,  2.1369e-01,  5.6939e-01,  7.0444e-01,\n",
            "         -2.0261e+00, -2.1776e-01, -6.6527e-03, -4.1903e-01,  1.1090e+00,\n",
            "         -1.8227e+00,  1.4987e+00,  1.0546e+00, -1.1485e+00,  9.9384e-01,\n",
            "         -3.1150e-01, -4.5779e-01, -2.1282e+00,  7.7486e-01, -3.4859e-02,\n",
            "         -1.3344e+00, -1.8486e+00, -1.1954e+00, -8.8573e-01, -1.3607e+00,\n",
            "         -9.8877e-01,  1.0558e+00,  2.5752e-01,  4.6830e-01,  9.9545e-01,\n",
            "          1.4817e-01, -1.4934e+00,  1.4341e+00,  8.5578e-01, -1.9900e+00,\n",
            "          2.9635e-01, -3.8722e-01, -1.6988e+00, -1.9215e+00, -2.1690e-01,\n",
            "         -1.1294e+00,  4.9332e-01, -1.2497e+00, -4.3750e-01,  1.0533e+00,\n",
            "         -1.0945e+00, -1.5449e+00, -3.5938e-01, -9.3079e-01,  1.4853e+00,\n",
            "         -4.8568e-01,  1.4073e+00,  1.7496e+00,  1.9481e+00, -2.3231e-04,\n",
            "         -4.1481e-02,  1.6028e-01, -7.4290e-01, -1.0349e+00, -5.5120e-01,\n",
            "         -3.5135e-01,  5.0822e-01,  2.3828e-01,  5.4325e-01, -6.4696e-01,\n",
            "          2.3792e-01, -1.1839e+00, -3.1790e-01]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(token_embedding_layer(torch.tensor([3])))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpBwczWFWjT2"
      },
      "source": [
        "### POSITIONAL EMBEDDINGS (ENCODING WORD POSITIONS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezI3eeHVWjT2"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    \n",
        "Using the token_embedding_layer above, if we sample data from the data loader, we\n",
        "embed each token in each batch into a 256-dimensional vector. If we have a batch size of 8\n",
        "with four tokens each, the result will be an 8 x 4 x 256 tensor.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjzFDd52WjT2"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Let's instantiate the data loader ( Data sampling with a sliding window),\n",
        "first:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "ISp4HlHCWjT2"
      },
      "outputs": [],
      "source": [
        "max_length = 4\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=8, max_length=max_length,\n",
        "    stride=max_length, shuffle=False\n",
        ")\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sviI-olpWjT2",
        "outputId": "de2ecb5f-ee2b-4ae0-e502-af24715f027b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[   44,   374,    13,   290],\n",
            "        [ 9074,    13,   360,  1834],\n",
            "        [ 1636,    11,   286,  1271],\n",
            "        [ 1440,    11,  4389, 16809],\n",
            "        [ 9974,    11,   547,  6613],\n",
            "        [  284,   910,   326,   484],\n",
            "        [  547,  7138,  3487,    11],\n",
            "        [ 5875,   345,   845,   881]])\n",
            "\n",
            "Inputs shape:\n",
            " torch.Size([8, 4])\n"
          ]
        }
      ],
      "source": [
        "print(\"Token IDs:\\n\", inputs)\n",
        "print(\"\\nInputs shape:\\n\", inputs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9aGp9SBWjT2",
        "outputId": "edad3e20-d06e-4b4c-d84b-381574eabd28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 768])\n"
          ]
        }
      ],
      "source": [
        "token_embeddings = token_embedding_layer(inputs)\n",
        "print(token_embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "5PBNTp0RWjT2"
      },
      "outputs": [],
      "source": [
        "context_length = max_length\n",
        "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ji4Nu3_NWjT3",
        "outputId": "e0adaccd-aff1-4f0a-dfd0-2c280fb85a17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 768])\n"
          ]
        }
      ],
      "source": [
        "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
        "print(pos_embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPMhJOsQWjT3",
        "outputId": "2223f86d-5254-48f9-ccca-326ab6ec3571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 768])\n"
          ]
        }
      ],
      "source": [
        "input_embeddings = token_embeddings + pos_embeddings\n",
        "print(input_embeddings.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Rqi53dVWjUE"
      },
      "source": [
        "### IMPLEMENTING MULTI-HEAD ATTENTION WITH WEIGHT SPLITS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "G5ZBJNu8WjUE"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fq9Dxx9HWjUE",
        "outputId": "216dd0ba-00be-4c44-e300-866cc8b0d8a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 6])\n",
            "tensor([[[ 0.1569, -0.0873,  0.0210,  0.0215, -0.3243, -0.2518],\n",
            "         [ 0.1117, -0.0547,  0.0406, -0.0213, -0.3251, -0.2993],\n",
            "         [ 0.1196, -0.0491,  0.0318, -0.0635, -0.2788, -0.2578]],\n",
            "\n",
            "        [[ 0.1569, -0.0873,  0.0210,  0.0215, -0.3243, -0.2518],\n",
            "         [ 0.1117, -0.0547,  0.0406, -0.0213, -0.3251, -0.2993],\n",
            "         [ 0.1196, -0.0491,  0.0318, -0.0635, -0.2788, -0.2578]]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "context_vecs.shape: torch.Size([2, 3, 6])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "# Define the tensor with 3 rows and 6 columns\n",
        "inputs = torch.tensor(\n",
        "    [[0.43, 0.15, 0.89, 0.55, 0.87, 0.66],  # Row 1\n",
        "     [0.57, 0.85, 0.64, 0.22, 0.58, 0.33],  # Row 2\n",
        "     [0.77, 0.25, 0.10, 0.05, 0.80, 0.55]]  # Row 3\n",
        ")\n",
        "\n",
        "batch = torch.stack((inputs, inputs), dim=0)\n",
        "print(batch.shape)\n",
        "\n",
        "batch_size, context_length, d_in = batch.shape\n",
        "d_out = 6\n",
        "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
        "context_vecs = mha(batch)\n",
        "print(context_vecs)\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDf2QyQiWjUF"
      },
      "source": [
        "## IMPLEMENTING A GPT MODEL FROM SCRATCH TO GENERATE TEXT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "_TFMl-VmWjUF"
      },
      "outputs": [],
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"context_length\": 1024, # Context length\n",
        "    \"emb_dim\": 768,         # Embedding dimension\n",
        "    \"n_heads\": 12,          # Number of attention heads\n",
        "    \"n_layers\": 12,         # Number of layers\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": False       # Query-Key-Value bias\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNOfBukyWjUN"
      },
      "source": [
        "### THE BUILDING BLOCKS: LAYER NORMALIZATION, GELU AND FEED-FORWARD NEURAL NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "bN-EFwI4WjUN"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n",
        "            GELU(), ## Activation\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "AA_7BsBXWjUN"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        # 2*4*768\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x\n",
        "        # 2*4*768"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h7PQX_aWjUN"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "\n",
        "The class also implements the forward pass, where each component is followed by a\n",
        "shortcut connection that adds the input of the block to its output. This critical feature helps\n",
        "gradients flow through the network during training and improves the learning of deep\n",
        "models\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_oLld4SWjUN"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "Using the GPT_CONFIG_124M dictionary we defined earlier, let's instantiate a transformer\n",
        "block and feed it some sample data\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "In3pslG_WjUN"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "Create sample input of shape [batch_size, num_tokens, emb_dim]\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sfqOVyJWjUO",
        "outputId": "93974a5e-c0f4-464d-e9c7-5c486a806fb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "x = torch.rand(2, 4, 768) #A\n",
        "block = TransformerBlock(GPT_CONFIG_124M)\n",
        "output = block(x)\n",
        "print(\"Input shape:\", x.shape)\n",
        "print(\"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVFDIHNzWjUO"
      },
      "source": [
        "## GPT ARCHITECTURE PART 6: ENTIRE GPT MODEL ARCHITECTURE IMPLEMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "nQjC9OuEWjUO"
      },
      "outputs": [],
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"context_length\": 1024, # Context length\n",
        "    \"emb_dim\": 768,         # Embedding dimension\n",
        "    \"n_heads\": 12,          # Number of attention heads\n",
        "    \"n_layers\": 12,         # Number of layers\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": False       # Query-Key-Value bias\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdBwGmJ4WjUO"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    \n",
        "LAYER NORMALIZATION AND FEEDFORWARD NEURAL NETWORK CLASS\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "w62-9jvPWjUO"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n",
        "            GELU(), ## Activation\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmOl5RioWjUO"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    \n",
        "TRANSFORMER CLASS\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "UW2TNoPvWjUO"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        # 2*4*768\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x\n",
        "        # 2*4*768"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "ZPRmyRr2WjUO"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjsNPJw8WjUP"
      },
      "source": [
        "## GPT ARCHITECTURE PART 7: GENERATING TEXT FROM OUTPUT TOKENS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_kyBIGzWjUP"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "Let us implement the token-generation process as follows:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "4ovKsZhSWjUP"
      },
      "outputs": [],
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (batch, n_tokens) array of indices in the current context\n",
        "\n",
        "    ###Input batch:\n",
        " ###tensor([[6109, 3626, 6100,  345],\n",
        "        ##[6109, 1110, 6622,  257]])\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond) ### batch, n_tokens, vocab_size\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest probability value\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjzWqCQYWjUP",
        "outputId": "f34e4ec7-ae2f-4a9e-cdcc-4cbe08fed317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded: [15496, 11, 314, 716]\n",
            "encoded_tensor.shape: torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "start_context = \"Hello, I am\"\n",
        "encoded = tokenizer.encode(start_context)\n",
        "print(\"encoded:\", encoded)\n",
        "encoded_tensor = torch.tensor(encoded).unsqueeze(0) #A\n",
        "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXAKtMTrWjUQ",
        "outputId": "09cea71d-d075-4ad6-d22c-859f2056ba26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: tensor([[15496,    11,   314,   716, 15714, 25557, 37109, 11641, 45846, 11365]])\n",
            "Output length: 10\n"
          ]
        }
      ],
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval() #A\n",
        "out = generate_text_simple(\n",
        "model=model,\n",
        "idx=encoded_tensor,\n",
        "max_new_tokens=6,\n",
        "context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "print(\"Output:\", out)\n",
        "print(\"Output length:\", len(out[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSL1c9msWjUQ"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "Using the .decode method of the tokenizer, we can convert the IDs back into text:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wes3I4BWjUQ",
        "outputId": "9d4deea4-cb77-4c55-b43d-0c148f3c006a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, I am distinguishcot Tartaeda slamsitivity\n"
          ]
        }
      ],
      "source": [
        "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
        "print(decoded_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLUuUpXbWjUQ",
        "outputId": "7d06cdd7-5c64-4215-869b-1880175d5b99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves youacebook overnight bullpen (. detachment Mc Ren Zi intest Previous\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_context = \"Every effort moves you\"\n",
        "\n",
        "\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(start_context, tokenizer),\n",
        "    max_new_tokens=10,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdcIn3Q7WjUQ"
      },
      "source": [
        "### Calculating the text generation loss: cross-entropy and perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "e5geiop0WjUQ"
      },
      "outputs": [],
      "source": [
        "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
        "                       [40,    1107, 588]])   #  \"I really like\"]\n",
        "\n",
        "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
        "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3EicoKPWjUQ",
        "outputId": "0af9203e-1f4c-4418-934e-2519c9de753a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 50257])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    logits = model(inputs)\n",
        "\n",
        "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
        "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDKRiID8WjUR",
        "outputId": "a0d3bf71-c859-4e66-94fb-3e377bc16ee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[[12887],\n",
            "         [15721],\n",
            "         [ 5679]],\n",
            "\n",
            "        [[  126],\n",
            "         [34728],\n",
            "         [32247]]])\n"
          ]
        }
      ],
      "source": [
        "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "print(\"Token IDs:\\n\", token_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jofcp1-9WjUR",
        "outputId": "9c21a905-3e1d-41ba-961f-1065fde119d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Targets batch 1:  effort moves you\n",
            "Outputs batch 1:  WETra follows\n"
          ]
        }
      ],
      "source": [
        "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
        "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIRTOXrZWjUR"
      },
      "source": [
        "### Cross-entropy loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aYn_eDeWjUR"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "The token probabilities corresponding to the target indices are as follows:\n",
        "\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlK_qzxEWjUR",
        "outputId": "2f7eb926-4ee6-4e34-d341-7d4d904b0542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1: tensor([1.1861e-05, 1.6859e-05, 1.8356e-05])\n",
            "Text 2: tensor([3.7964e-05, 1.4140e-05, 1.2491e-05])\n"
          ]
        }
      ],
      "source": [
        "text_idx = 0\n",
        "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 1:\", target_probas_1)\n",
        "\n",
        "text_idx = 1\n",
        "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 2:\", target_probas_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeEIy8TOWjUR",
        "outputId": "25eb1aed-733f-4e24-9c09-a4ef97724afb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-11.3422, -10.9906, -10.9056, -10.1789, -11.1665, -11.2905])\n"
          ]
        }
      ],
      "source": [
        "# Compute logarithm of all token probabilities\n",
        "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
        "print(log_probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awC2-NZnWjUR",
        "outputId": "56460bf6-9bb0-47d7-933e-c7317a0efd14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-10.9791)\n"
          ]
        }
      ],
      "source": [
        "# Calculate the average probability for each token\n",
        "avg_log_probas = torch.mean(log_probas)\n",
        "print(avg_log_probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMtT6QPqWjUR",
        "outputId": "5b45fb82-9445-4680-bd82-f62a4be0a37a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.9791)\n"
          ]
        }
      ],
      "source": [
        "neg_avg_log_probas = avg_log_probas * -1\n",
        "print(neg_avg_log_probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJbpJUZaWjUR",
        "outputId": "b20c191a-4915-4e1d-96ad-620d08e26da8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape: torch.Size([2, 3, 50257])\n",
            "Targets shape: torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
        "print(\"Logits shape:\", logits.shape)\n",
        "\n",
        "# Targets have shape (batch_size, num_tokens)\n",
        "print(\"Targets shape:\", targets.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJwMGknpWjUR",
        "outputId": "ae8771a9-15ec-49e8-a4ec-27c45178bc68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattened logits: torch.Size([6, 50257])\n",
            "Flattened targets: torch.Size([6])\n"
          ]
        }
      ],
      "source": [
        "logits_flat = logits.flatten(0, 1)\n",
        "targets_flat = targets.flatten()\n",
        "\n",
        "print(\"Flattened logits:\", logits_flat.shape)\n",
        "print(\"Flattened targets:\", targets_flat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb70N3sEWjUR",
        "outputId": "282bd3a0-d2c0-4839-c949-4f4c21d2593b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.9791)\n"
          ]
        }
      ],
      "source": [
        "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o_B0gk4WjUS"
      },
      "source": [
        "### Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5y1DZwLWjUS",
        "outputId": "810791a3-139b-40af-b252-8301166a1498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(58633.0312)\n"
          ]
        }
      ],
      "source": [
        "perplexity = torch.exp(loss)\n",
        "print(perplexity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeJAHWn_WjUS"
      },
      "source": [
        "### Calculating the training and validation set losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "2vu4gOeJWjUS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "file_path = \"harrypotter.txt\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "  text_data = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qx5gOOyNWjUS",
        "outputId": "b3043719-d49f-42c1-b69a-d2848e3be0c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M r. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly nor\n"
          ]
        }
      ],
      "source": [
        "# First 100 characters\n",
        "print(text_data[:99])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCZUbJMyWjUS",
        "outputId": "c23ede71-82d0-4920-ce57-5ae1ab376762"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w were not allowed to use magic at home. Im going to have a lot of fun with Dudley this summer. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Last 100 characters\n",
        "print(text_data[-99:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "SdSBhs1eWjUS"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HWv44iWWjUT",
        "outputId": "8a3456bb-103c-4513-801e-c7bdd0351718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Characters: 439478\n",
            "Tokens: 124336\n"
          ]
        }
      ],
      "source": [
        "total_characters = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "\n",
        "print(\"Characters:\", total_characters)\n",
        "print(\"Tokens:\", total_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fii5ZFEsWjUU"
      },
      "source": [
        "### Implementing the DataLoader:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "LpftvL73WjUU"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "JoBUXJsEWjUU"
      },
      "outputs": [],
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,   # Vocabulary size\n",
        "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
        "    \"emb_dim\": 768,        # Embedding dimension\n",
        "    \"n_heads\": 12,         # Number of attention heads\n",
        "    \"n_layers\": 12,        # Number of layers\n",
        "    \"drop_rate\": 0.1,      # Dropout rate\n",
        "    \"qkv_bias\": False      # Query-key-value bias\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "vjvSCeuQWjUV"
      },
      "outputs": [],
      "source": [
        "# Train/validation ratio\n",
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "awZlHFSlWjUV"
      },
      "outputs": [],
      "source": [
        "# Sanity check\n",
        "\n",
        "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "    print(\"Not enough tokens for the training loader. \"\n",
        "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
        "          \"increase the `training_ratio`\")\n",
        "\n",
        "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "    print(\"Not enough tokens for the validation loader. \"\n",
        "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
        "          \"decrease the `training_ratio`\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxfFLEDXWjUV"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "We use a relatively small batch size to reduce the computational resource demand, and because the dataset is very small to begin with.\n",
        "\n",
        "Llama 2 7B was trained with a batch size of 1024, for example.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjUFooc7WjUV"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "An optional check that the data was loaded correctly:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmDJgOmYWjUV",
        "outputId": "32f07fba-5034-488a-c1f8-7c53c311db46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "Validation loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([1, 256]) torch.Size([1, 256])\n",
            "218\n",
            "25\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for x, y in train_loader:\n",
        "    print(x.shape, y.shape)\n",
        "\n",
        "print(\"\\nValidation loader:\")\n",
        "for x, y in val_loader:\n",
        "    print(x.shape, y.shape)\n",
        "\n",
        "print(len(train_loader))\n",
        "print(len(val_loader))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jX9tt3yWjUV"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "An optional check that the data was loaded correctly:\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT8SSn5TWjUV",
        "outputId": "aea6c105-b723-4b78-daf4-c26262c53743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training tokens: 111616\n",
            "Validation tokens: 12544\n",
            "All tokens: 124160\n"
          ]
        }
      ],
      "source": [
        "train_tokens = 0\n",
        "for input_batch, target_batch in train_loader:\n",
        "    train_tokens += input_batch.numel()\n",
        "\n",
        "val_tokens = 0\n",
        "for input_batch, target_batch in val_loader:\n",
        "    val_tokens += input_batch.numel()\n",
        "\n",
        "print(\"Training tokens:\", train_tokens)\n",
        "print(\"Validation tokens:\", val_tokens)\n",
        "print(\"All tokens:\", train_tokens + val_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywaZe5_yWjUV"
      },
      "source": [
        "### Here is the GPT Model class we coded earlier. We will need this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "tvfq5UmMWjUV"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval();  # Disable dropout during inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr3yqrRGWjUV"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Next, we implement a utility function to calculate the cross-entropy loss of a given batch.\n",
        "\n",
        "In addition, we implement a second utility function to compute the loss for a user-specified number of batches in a data loader.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "Y6-DZaTdWjUW"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hjvdh9vlWjUW"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "If you have a machine with a CUDA-supported GPU, the LLM will train on the GPU without making any changes to the code.\n",
        "    \n",
        "Via the device setting, we ensure that the data is loaded onto the same device as the LLM model.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcIhFStGWjUW",
        "outputId": "694a7b00-3150-4452-d893-521ed26a89de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device.\n",
            "Training loss: 5.819272168185733\n",
            "Validation loss: 5.805115718841552\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Using {device} device.\")\n",
        "\n",
        "\n",
        "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
        "\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
        "\n",
        "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
        "    train_loss = calc_loss_loader(train_loader, model, device)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dq0-BrpkWjUW"
      },
      "source": [
        "## TRAINING LOOP FOR THE LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "rciuefuVWjUW"
      },
      "outputs": [],
      "source": [
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "H9J062AgWjUW"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "GZP2uVZhWjUW"
      },
      "outputs": [],
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "KZs3JaJYWjUW",
        "outputId": "eeab5e0f-9daa-460e-b691-aabb60081c31"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4136191010>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPTModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGPT_CONFIG_124M\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 1\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvlAyt10WjUX"
      },
      "source": [
        "## DECODING STRATEGIES TO CONTROL RANDOMNESS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrVpWIBjWjUX",
        "outputId": "4ff2761e-2f85-483c-d914-fefeeb4c3935"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 186,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(\"cpu\")\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUlsWNWdWjUX",
        "outputId": "e3717ba2-d042-4e66-ec8d-464a2caa1d64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output text:\n",
            " Every effort moves you rentingetic wasn refres RexMeCHicular stren Mortgage TT remember gard ACTIONSussedOND Land Engeleddedemate breaths proxies GalaxyForm\n"
          ]
        }
      ],
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "    max_new_tokens=25,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fheQOvpWjUZ"
      },
      "source": [
        "### Merge Temperature Scaling and Top-k sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toF1324xWjUa"
      },
      "outputs": [],
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfLrS2cLWjUa"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "\n",
        "Let's now see this new generate function in action:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ibjVaC_WjUa",
        "outputId": "eaeaf2fd-cfe3-4b98-cd8a-d2916b8fb23d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output text:\n",
            " Every effort moves youEveryiliaralso stabbed OrleansAllowsean 52anche crime winter unbeaten quoteembedreportprint earning\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        "    top_k=25,\n",
        "    temperature=1.4\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1Uaq10hWjUa"
      },
      "source": [
        "## LOADING AND SAVING MODEL WEIGHTS IN PYTORCH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTd45sujWjUa"
      },
      "outputs": [],
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "torch.save(model.state_dict(), \"model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFJnCynjWjUb",
        "outputId": "4ed706fb-ece0-4368-cf4b-edc0bf9e38ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 204,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(torch.load(\"model.pth\"))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGvfW-CKWjUb"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "torch.save({\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    },\n",
        "    \"model_and_optimizer.pth\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4Lzmf1TWjUc"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train();"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}